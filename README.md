# BiasShield
A machine learning toolkit that identifies, scores, and explains toxic or biased text using real-world datasets, SHAP interpretability, and PDF reporting.
